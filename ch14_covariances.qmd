# Adventures in Covariance {#Covariance}

```{r}
#| include: false
library(conflicted)
library(dplyr)
library(tidyr)
library(tidybayes)
library(rethinking)
library(brms)
library(loo)
# library(modelr)
library(skimr)
library(simpr)
library(posterior)
library(scales)
library(dagitty)
library(ggplot2)
library(ggdag)
# library(ggnetwork)
library(ggraph)
library(ggtree)
library(tidygraph)
library(bayesplot)
library(patchwork)
library(paletteer)
library(ape)
```

Some options to facilitate the computations

```{r}
#  For execution on a local, multicore CPU with excess RAM
options(mc.cores = parallel::detectCores())
#  To avoid recompilation of unchanged Stan programs
rstan::rstan_options(auto_write = TRUE)
# Found more than one class "stanfit" in cache; using the first, from namespace 'rethinking'
conflicted::conflicts_prefer(
  rstan::stanfit,
  dplyr::filter,
  brms::ar,
  rethinking::circle,
  loo::compare,
  brms::dstudent_t,
  dagitty::edges,
  simpr::expand,
  dplyr::lag,
  brms::LOO,
  posterior::mad,
  posterior::match,
  brms::pstudent_t,
  brms::qstudent_t,
  brms::rhat,
  ape::rotate,
  rethinking::rstudent,
  brms::rstudent_t,
  posterior::sd,
  brms::stancode,
  posterior::var,
  brms::WAIC,
  dplyr::where,
  .quiet = TRUE)
```

The default theme used by `ggplot2`

```{r}
theme_set(ggthemes::theme_stata(base_size = 11, base_family = "sans", 
                                scheme = "s2color"))
```

## Varying slopes by construction

### Simulate the population

```{r}
simCafes <- list()
simCafes <- within(simCafes, {
  # a := average morning wait time
  # b := average difference afternoon wait time
  Mu <- c("a" = 3.5, "b" = -1)
  
  # a := std dev of intercepts
  # b := std dev of slopes
  sigmas <- c("a" = 1, "b" = 0.5)
  
  # correlation between intercepts and slopes
  rho <- -0.7
  
  # covariance of a and b
  cov_ab <- prod(sigmas) * rho
})
```

McElreath mentions a difficulty using the `matrix` function. He misses the argument `byrow` which resolve this.

```{r}
# use byrow = TRUE to solve McElrath's issue
matrix(1:4, nrow = 2, ncol = 2, byrow = TRUE)
```

we get the covariance matrix `sigma` as follows

```{r}
simCafes <- within(simCafes, {
  n_cafes <- 20L
  # matrix of correlation
  Rho <- matrix(c(1, rho, rho, 1), nrow = 2)
  
  # covariance matrix
  Sigma <- diag(sigmas) %*% Rho %*% diag(sigmas)
})

```

and we simulate the bivariate normal distribution


```{r}
simCafes <- within(simCafes, {
  set.seed(1409)
  vary_effects <- simpr::specify(
    a = ~ MASS::mvrnorm(n = simCafes$n_cafes, mu = simCafes$Mu, Sigma = simCafes$Sigma)) |>
    generate(1) |>
    pull(sim) |>
    as.data.frame() |>
    mutate(cafe = 1:n())
})
simCafes$vary_effects |>
  skim() |>
  select(-n_missing, -complete_rate) |>
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 2))
```

and we plot the simulated data which represents the intercept and slope

```{r}
#| fig-cap: "Figure 14.2"
simCafes$vary_effects |>
  ggplot(aes(x = a, y = b)) +
  geom_point(shape = 1, size = 3, color = "purple") +
  lapply(X = 1:5 / 5, FUN = function(x) {
      stat_ellipse(type = "norm", level = x, linetype = "dotted", linewidth = 0.25)}) +
  theme(legend.position = "none") +
  labs(title = sprintf("Distribution of intercept and slopes for %d cafes", 
                       simCafes$n_cafes),
       x = "intercepts (a_cafe)", y = "slope (b_cafe)")
```

### Simulate the observations (visits by cafe)

Now using the simulated intercepts and slopes, we create the simulated visits to each cafe.

```{r}
simCafes <- within(simCafes, {
  n_visits <- 10  # nb of visits to each cafe by robot
  sigma <- 0.5  # std dev within cafes
  
  set.seed(1409)
  data <- vary_effects |>
    expand_grid(simCafes$cafe, "visit" = seq_len(n_visits)) |>
    mutate(afternoon = rep(0:1, times = n()/2)) |>
    mutate(mu = a + b * afternoon) |>
    mutate(wait = rnorm(n = n(), mean = mu, sd = sigma))
})
# glimpse(simCafes$vary_effects)
# glimpse(simCafes$data)
```

and plot the simulated observations.

```{r}
simCafes$data |>
  mutate(afternoon = if_else(afternoon == 0, "M", "A"),
         day = rep(rep(1:5, each = 2), times = simCafes$n_cafes),
         label = paste("cafe", simCafes$data$cafe)) |>
  filter(cafe %in% c(1, 5)) |>
  ggplot(aes(x = visit, y = wait, group = day)) +
  geom_point(aes(color = afternoon), size = 2) +
  geom_line(color = "green") +
  scale_color_manual(values = c("M" = "royalblue", "A" = "hotpink")) +
  theme(legend.position = "none") +
  labs(title = "Varying slopes simulation") +
  facet_wrap(~ label, ncol = 1)
```

### The varying slopes model

#### The model

$$
\begin{align*}
wait_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha_{cafe[i]} + \beta_{cafe[i]} \cdot afternoon_i \\
\begin{bmatrix}
\alpha_{cafe} \\
\beta_{cafe}
\end{bmatrix}
&\sim
\mathcal{MVNormal}(
\begin{bmatrix}
\alpha \\
\beta
\end{bmatrix}
,
\bf{\Sigma}
) \\
\bf{\Sigma} &=
\begin{bmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\beta}
\end{bmatrix}
\begin{bmatrix}
1 & \rho \\
\rho & 1
\end{bmatrix}
\begin{bmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\beta}
\end{bmatrix} \\
\alpha &\sim \mathcal{N}(0, 10) \\
\beta &\sim \mathcal{N}(0, 10) \\
\sigma &\sim \mathcal{HalfCauchy}(0, 1) \\
\sigma_{\alpha} &\sim \mathcal{HalfCauchy}(0, 1) \\
\sigma_{\beta} &\sim \mathcal{HalfCauchy}(0, 1) \\
\rho
&\sim \mathcal{LKJcorr}(K=2)
\end{align*}
$$

#### LKJ prior

We use the `ggdist` package to illustrate the LKJ distribution.

```{r}
#| fig-cap: "Figure 14.3"
lkj_dist <- list()
lkj_dist <- within(lkj_dist, {
  df <- crossing(K = 2:4, eta = c(1, 2, 4), x = seq(from = -1, to = 1, by = 0.05)) %>%
    mutate(dens = purrr::pmap_dbl(.l = ., 
                              .f = \(K, eta, x) ggdist::dlkjcorr_marginal(x = x, K = K, eta = eta))) |>
    mutate(
      id = K^eta,
      label_K = paste0("K==", K),
      label_eta = paste0("eta==", eta)) |>
    identity()
  
  p <- df |>
    ggplot(mapping = aes(x = x, y = dens, color = id)) +
    geom_line(size = 1) +
    scale_y_continuous(breaks = c(0, 0.5, 1)) +
    scale_color_paletteer_c("palr::sst_pal") +
    theme(legend.position = "none") +
    facet_grid(facets = label_eta ~ label_K, scales= "fixed", labeller = label_parsed) +
    labs(title = "Lewandowski-Kurowicka-Joe Distribution",
         x = "correlation", y = "density")
})
# lkj_dist$df |>
#   glimpse()
lkj_dist$p
```

```{r}
#| label: "ch14_fit14_01"
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit14_01 <- xfun::cache_rds({
  out <- brm(
    data = simCafes$data,
    family = gaussian,
    formula = wait ~ 1 + afternoon + (1 + afternoon | cafe),
    prior = c(
      prior(normal(5, 2), class = Intercept),
      prior(normal(-1, 0.5), class = b),
      prior(exponential(1), class = sd),
      prior(exponential(1), class = sigma),
      prior(lkj(2), class = cor)),
    sample_prior = TRUE,
    iter = 1000, warmup = 500, chains = 2,
    cores = detectCores(), seed = 1423)
  add_criterion(out, c("loo", "waic"))},
  file = "ch14_fit14_01", rerun = FALSE)
tictoc::toc()
```

```{r}
#| label: "ch14_post14_01"
post14_01 <- list()
post14_01 <- within(post14_01, {
  prior <- prior_draws(x = fit14_01)
  
  post <- tidy_draws(model = fit14_01)
  
  # dataframe of correlations to plot
  corr = data.frame("value" = c(prior$cor_cafe, post$cor_cafe__Intercept__afternoon),
                    "id" = c(rep("prior", nrow(prior)), rep("post", nrow(post))))

  coefs <- fit14_01 |>
    spread_draws(b_Intercept, b_afternoon, r_cafe[cafe, term]) |>
    pivot_wider(id_cols = c("b_Intercept", "b_afternoon", "cafe"),
                names_from = "term", values_from = "r_cafe") |>
    group_by(cafe) |>
    summarize(b_Intercept = mean(b_Intercept), b_afternoon = mean(b_afternoon),
              r_afternoon = mean(afternoon), r_Intercept = mean(Intercept)) |>
    mutate(Intercept = b_Intercept + r_Intercept,
           afternoon = b_afternoon + r_afternoon) |>
    select(cafe, Intercept, afternoon) |>
    identity()
  all <- simCafes$vary_effects |>
    rename("Intercept" = a, "afternoon" = b)
  
  all <- bind_rows("real" = all, "post" = coefs, .id = "id")
})
# glimpse(post14_01$post)
# glimpse(post14_01$coefs)
# glimpse(post14_01$all)
```

```{r}
#| label: "ch14_plot14_01"
#| fig-cap: "Figure 14.4"
plot14_01 <- list()
plot14_01 <- within(plot14_01, {
  cor <- post14_01$corr |> 
    ggplot(aes(x = value, color = id, linetype = id)) +
    geom_density(size = 1, adjust = 0.75) +
    scale_color_manual(values = c("prior" = "black", "post" = "blue")) +
    scale_linetype_manual(values = c("prior" = "longdash", "post" = "solid")) +
    theme(legend.position = c(0.8, 0.8), legend.title = element_blank()) +
    labs(title = "Posterior and Prior distribution of the correlation",
         x = "correlation")
})
plot14_01$cor
```

```{r}
#| label: "ch14_pred14_01"
pred14_01 <- list()
pred14_01 <- within(pred14_01, {
  pred_df <- simCafes$data |>
    group_by(cafe, afternoon) |>
    summarise(mwait = mean(wait)) |>
    add_predicted_draws(object = fit14_01) |>
    mean_qi(.width = 0.89) |>
    mutate(term = if_else(afternoon == 0, "Intercept", "afternoon"))
  
  real <- pred_df |>
    select(cafe, term, mwait) |>
    pivot_wider(id_cols = cafe, names_from = term, values_from = mwait)
  
  pred <- pred_df |>
    select(cafe, term, .prediction) |>
    pivot_wider(id_cols = cafe, names_from = term, values_from = .prediction)
  
  all <- bind_rows("real" = real, "pred" = pred, .id = "id")
})
# glimpse(pred14_01$all)
# glimpse(simCafes$data)
```

```{r}
#| fig-cap: "Figure 14.5"
plot14_01 <- within(plot14_01, {
  coefs <- post14_01$all |>
    ggplot(mapping = aes(x = Intercept, y = afternoon, group = cafe, color = id)) +
    lapply(X = 1:5 / 5, FUN = function(x) {
      stat_ellipse(data = post14_01$all, mapping = aes(x = Intercept, y = afternoon),
                   inherit.aes = FALSE,
                   geom = "polygon", type = "norm", level = x, linewidth = 1/5,
                 color = "dodgerblue", fill = "transparent")}) +
    geom_point() +
    geom_line(color = "black") +
    scale_color_paletteer_d("awtools::spalette", direction = 1) +
    theme(legend.position = c(0.2, 0.2),
          legend.title = element_blank()) +
    labs(title = "Coefficients and shrinkage",
         x = "Intercept", y = "Slope")
    
  
  wait <- pred14_01$all |>
    ggplot(mapping = aes(x = Intercept, y = afternoon, group = cafe, color = id)) +
    lapply(X = 1:5 / 5, FUN = function(x) {
      stat_ellipse(data = pred14_01$all, mapping = aes(x = Intercept, y = afternoon),
                   inherit.aes = FALSE,
                   geom = "polygon", type = "norm", level = x, linewidth = 1/5,
                 color = "dodgerblue", fill = "transparent")}) +
    geom_point() +
    geom_line(color = "black") +
    scale_color_paletteer_d("awtools::spalette", direction = -1) +
    theme(legend.position = c(0.8, 0.2),
          legend.title = element_blank()) +
    labs(title = "Waiting time and shrinkage",
         x = "morning wait", y = "afternoon wait")
})
# plot14_01$coefs
wrap_plots(plot14_01[c("coefs", "wait")]) +
  plot_annotation(title = "Shrinkage in two dimensions")

```

## Advanced varying slopes

```{r}
#| label: "ch14_dataChimp"
data(chimpanzees)
dataChimp <- chimpanzees |>
  mutate(block = factor(block),
         actor = factor(actor),
         treatment = factor(1 + prosoc_left + 2 * condition, levels = 1:4,
                            labels = c("AR", "AL", "PR", "PL")))
rm(chimpanzees)
dataChimp |>
  skim() |>
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 2))
```

#### The model



$$
\begin{align*}
L_i &\sim \mathcal{Binomial}(1, p_i) \\
logit(p_i) &\sim \gamma_{treatment[i]} + \alpha_{actor[i], treatment[i]} + \beta_{block[i], treatment[i]} \\
\gamma_{treatment[i]} &\sim \mathcal{N}(0, 1), \, \text{for } i = 1 \ldots 4 \\


\begin{bmatrix}
\alpha_{j, 1} \\
\alpha_{j, 2} \\
\alpha_{j, 3} \\
\alpha_{j, 4}
\end{bmatrix}
&\sim
\mathcal{MVNormal}(
\begin{bmatrix}
0 \\
0 \\
0 \\
0\\
\end{bmatrix}
,
\bf{\Sigma_{actor}}
) \\


\begin{bmatrix}
\beta_{j, 1} \\
\beta_{j, 2} \\
\beta_{j, 3} \\
\beta_{j, 4}
\end{bmatrix}
&\sim
\mathcal{MVNormal}(
\begin{bmatrix}
0 \\
0 \\
0 \\
0 \\
\end{bmatrix}
,
\bf{\Sigma_{block}}
) \\



\bf{\Sigma_{actor}} &=
\begin{bmatrix}
\sigma_{factor} & 0 \\
0 & \sigma_{factor}
\end{bmatrix}
\cdot
\begin{bmatrix}
1 & \rho_{factor} \\
\rho_{factor} & 1
\end{bmatrix}
\cdot
\begin{bmatrix}
\sigma_{factor} & 0 \\
0 & \sigma_{factor}\\
\end{bmatrix} \\



\bf{\Sigma_{block}} &=
\begin{bmatrix}
\sigma_{block} & 0 \\
0 & \sigma_{block}
\end{bmatrix}
\cdot
\begin{bmatrix}
1 & \rho_{block} \\
\rho_{block} & 1
\end{bmatrix}
\cdot
\begin{bmatrix}
\sigma_{block} & 0 \\
0 & \sigma_{block}\\
\end{bmatrix} \\



\sigma_{actor, j} &\sim \mathcal{Exponential}(1), \, \text{for } i = 1 \ldots 4 \\
\sigma_{block, j} &\sim \mathcal{Exponential}(1), \, \text{for } i = 1 \ldots 4 \\


\rho_{actor}, \rho_{block} &\sim \mathcal{LKJcorr}(2)

\end{align*}
$$



We don't do model m14.2 since it is only done to illustrate centralized vs non-centralized parametrization and that `brms` uses only non-centralized parametrization.


```{r}
#| label: "ch14_fit14_03"

tictoc::tic(msg = sprintf("run time of %s, use the cache.", "80 secs."))
fit14_03 <- xfun::cache_rds({
  out <- brm(
    data = dataChimp,
    family = bernoulli,
    formula = bf(pulled_left ~ 0 + treatment + (0 + treatment | actor) + (0 + treatment | block)),
    prior = c(
      prior(normal(0, 1), class = b),
      prior(exponential(1), class = sd, group = actor),
      prior(exponential(1), class = sd, group = block),
      prior(lkj(2), class = cor, group = actor),
      prior(lkj(2), class = cor, group = block)),
    iter = 1000, warmup = 500, chains = 2,
    cores = detectCores(), seed = 1427)
  add_criterion(out, c("loo", "waic"))},
  file = "ch14_fit14_03", rerun = FALSE)
tictoc::toc()
```



The plot is slightly different than what McElreath has. The open circle represent the actual results and the solid circles are the predicted mean.

```{r}
#| label: "ch14_plot14_03"
#| fig-cap: "Figure 14.7"
plot14_03 <- list()
plot14_03 <- within(plot14_03, {

  df <- dataPredicted <- dataChimp |>
    group_by(actor, treatment, block) |>
    summarize(prop = mean(pulled_left)) |>
    ungroup() |>
    add_epred_draws(fit14_03) |>
    summarize(prop = mean(prop),
              mean_qi(.epred, .width = 0.89) ) |>
    rename(".epred" = y, ".lower" = ymin, ".upper" = ymax)
  
  # every block is different but, for plotting, we use the average of the blocks
  df <- df |>
    group_by(actor, treatment) |>
    summarize(
      prop = mean(prop),
      .epred = mean(.epred),
      .lower = mean(.lower),
      .upper = mean(.upper)) |>
    mutate(label = paste("actor", actor)) |>
    mutate(condition = if_else(substring(treatment, 1, 1) == "A", "alone", "partner"),
           condition = as.factor(condition),
           prosoc_left = if_else(substring(treatment, 2, 2) == "R", "right", "left"),
           prosoc_left = as.factor(prosoc_left)) |>
    mutate(label = paste("actor", actor))
    
    
    
  p <- df |>
    ggplot(aes(x = treatment, y = .epred,
                             group = prosoc_left, color = prosoc_left,
                             fill = prosoc_left)) +
    geom_line(linetype = "solid", size = 1) +
    geom_point(shape = 16, size = 3) +
    geom_line(aes(y = prop), linetype = "solid", size = 1) +
    geom_point(aes(y = prop), shape = 1, size = 3) +
    geom_errorbar(aes(ymin = .lower, ymax = .upper), width = 1/3) +
    geom_hline(yintercept = 0.5, color = "brown", linetype = 2) +
    scale_y_continuous(labels = scales::label_percent()) +
    scale_color_paletteer_d("jcolors::pal9") +
    coord_cartesian(ylim = c(0, 1)) +
    theme(legend.position = "bottom") +
    labs(title = "Posterior expected predictions with 89% CI",
         subtitle = "Open circles are actual results, solid circles are mean predictions.",
         x = NULL, y = "proportion pulled left") +
    facet_grid(. ~ label)
})
# glimpse(plot14_03$df)
plot14_03$p
```



## Instruments and Causal designs

```{r}
ggdag::dagify(E ~ U, W ~ U, W ~ E) |>
    ggdag::ggdag_classic(layout = "sugiyama", text_col = "royalblue") +
    ggdag::theme_dag_blank(
      panel.background = element_rect(fill = "snow", color = "snow"))
```



> In causal terms, an instrument variable is a variable that acts like a natural experiment on the exposure $E$.

In mathematical terms the instrumental variable $Q$ is characterized as follows:

1.  Independent of $U$, i.e. $Q \perp\!\!\!\perp U$
2.  Not independent of $E$, i.e. $Q \not\!\perp\!\!\!\perp E$
3.  Has no effect on $W$ except through $E$, also called the **exclusion condition**

> The exclusion restriction cannot be tested, and it is often implausible.

In the education and wage example, the simplest instrument variable $Q$ would be as follows

```{r}
ggdag::dagify(E ~ U + Q, W ~ U, W ~ E) |>
    ggdag::ggdag_classic(layout = "sugiyama", text_col = "royalblue") +
    ggdag::theme_dag_blank(
      panel.background = element_rect(fill = "snow", color = "snow"))
```

We now use a simulation to illustrate.

> With real data, you never know what the right anser is. This is h=why studying simulated examples is so important.

```{r}
#| label: "chap14_simInstrument"
simInstrument <- list()
simInstrument <- within(simInstrument, {
  set.seed(1429)
  df <- simpr::specify(
    U = ~ rnorm(n = 500),
    Q = ~ as.vector(scale(sample(x = 1:4, size = 500, replace = TRUE))),
    E = ~ as.vector(scale(rnorm(n = 500, mean = U + Q, sd = 1))),
    W = ~ as.vector(scale(rnorm(n = 500, mean = U + 0 * E, sd = 1)))) |>
    simpr::generate(1) |>
    pull(sim) |>
    as.data.frame()
})
simInstrument$df |>
  skim() |>
  select(-n_missing, -complete_rate) |>
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 2))
```

```{r}
#| echo: false
#| output: false
get_prior(
  data = simInstrument$df,
  formula = W ~ 1 + E,
  family = gaussian
)
```

```{r}
#| label: "ch14_fit14_04"
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "70 secs."))
fit14_04 <- xfun::cache_rds({
  out <- brm(
    data = simInstrument$df,
    family = gaussian,
    formula = W ~ 1 + E,
    prior = c(
      prior(normal(0, 0.2), class = Intercept),
      prior(normal(0, 0.5), class = b),
      prior(exponential(1), class = sigma)),
    iter = 1000, warmup = 500, chains = 2,
    cores = detectCores(), seed = 1429)
  add_criterion(out, c("loo", "waic"))},
  file = "ch14_fit14_04", rerun = FALSE)
tictoc::toc()
```

which gives us the results

```{r}
summarize_draws(fit14_04, "mean", "sd", ~quantile(.x, probs = c(0.055, 0.945)),
                default_convergence_measures()) |>
  filter(!grepl("^lp", x = variable)) |>
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 2),
         across(.cols = starts_with("ess"), .fns = as.integer))
```

The value $b_E$ should have been close to zero. The oncorrect value is caused by the confounding effect of $U$.

Now, lets see what happens when we include the instrumental variable $Q$.

```{r}
#| label: "ch14_fit14_05"
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit14_05 <- xfun::cache_rds({
  out <- brm(
    data = simInstrument$df,
    family = gaussian,
    formula = W ~ 1 + E + Q,
    prior = c(
      prior(normal(0, 0.2), class = Intercept),
      prior(normal(0, 0.5), class = b),
      prior(exponential(1), class = sigma)),
    iter = 1000, warmup = 500, chains = 2,
    cores = detectCores(), seed = 1429)
  add_criterion(out, c("loo", "waic"))},
  file = "ch14_fit14_05", rerun = FALSE)
tictoc::toc()
```

which gives us the results

```{r}
summarize_draws(fit14_05, "mean", "sd", ~quantile(.x, probs = c(0.055, 0.945)),
                default_convergence_measures()) |>
  filter(!grepl("^lp", x = variable)) |>
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 2),
         across(.cols = starts_with("ess"), .fns = as.integer))
```

The results are now even more confusing as the influence of $Q$ makes the effect of $E$ difficult to evaluate on its own.

So lets use the instrumental variable $Q$ again but taking into account the covariance of $E$ and $Q$. That is, we express the model as a \*multivariate statistical model as follows

$$
\begin{align*}
\begin{bmatrix}
W_i \\
E_i \\
\end{bmatrix}
&\sim
\mathcal{MVNormal}(
\begin{bmatrix}
\mu_{W, i} \\
\mu_{E, i}
\end{bmatrix}, 
\bf{\Sigma}
) \\
\mu_{W, i} &= \alpha_W + \beta_{EW}E_i \\
\mu_{E, i} &= \alpha_E + \beta_{QE}Q_i \\
\bf{\Sigma} &= 
\begin{bmatrix}
\sigma_W & 0 \\
0 & \sigma_E
\end{bmatrix}
\cdot
\begin{bmatrix}
1 & \rho \\
\rho & 1
\end{bmatrix}
\cdot
\begin{bmatrix}
\sigma_W & 0 \\
0 & \sigma_E
\end{bmatrix}
\\
\alpha_W, \alpha_E &\sim \mathcal{N}(0, 0.2) \\
\beta_{EW}, \beta_{QE} &\sim \mathcal{N}(0, 0.5) \\
\sigma_W, \sigma_E &\sim \mathcal{Exponential}(1) \\
\rho &\sim \mathcal{LKJ}(2)
\end{align*}
$$

```{r}
#| echo: false
#| output: false
get_prior(
  data = simInstrument$df,
  formula = bf(W ~ 1 + E) + bf(E ~ 1 + Q) + set_rescor(TRUE),
  family = gaussian
)
```

and the final fit is

```{r}
#| label: "ch14_fit14_06"
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "120 secs."))
fit14_06 <- xfun::cache_rds({
  out <- brm(
    data = simInstrument$df,
    family = gaussian,
    formula = bf(W ~ 1 + E) + bf(E ~ 1 + Q) + set_rescor(TRUE),
    prior = c(
      prior(normal(0, 0.2), class = Intercept, resp = E),
      prior(normal(0, 0.5), class = b, resp = E),
      prior(exponential(1), class = sigma, resp = E),
      prior(normal(0, 0.2), class = Intercept, resp = W),
      prior(normal(0, 0.5), class = b, resp = W),
      prior(exponential(1), class = sigma, resp = W),
      prior(lkj(2), class = rescor)),
    iter = 1000, warmup = 500, chains = 2,
    cores = detectCores(), seed = 1429)
  add_criterion(out, c("loo", "waic"))},
  file = "ch14_fit14_06", rerun = FALSE)
tictoc::toc()
```

which gives us the results

```{r}
summarize_draws(fit14_06, "mean", "sd", ~quantile(.x, probs = c(0.055, 0.945)),
                default_convergence_measures()) |>
  filter(!grepl("^lp", x = variable)) |>
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 2),
         across(.cols = starts_with("ess"), .fns = as.integer))
```

## Social relations as correlated varying effects

### Data

The research can be find in this [paper](https://research-information.bris.ac.uk/ws/portalfiles/portal/41942591/koster2014sn.pdf).
However I could not find what the variable $dlndist$ is. I suppose it it
the log of some distance . . but why is it negative? It doesn't matter, it is 
only used to color the edges of the network and not in the analysis per se.


```{r ch14_dataKL}
data(KosterLeckie, package = "rethinking")
dataKL <- list(
  "dyads" = kl_dyads,
  "houses" = kl_households)
rm(list = c("kl_dyads", "kl_households"))
dataKL$dyads <- dataKL$dyads |>
  # we only use these variable
  select(hidA, hidB, did, giftsAB, giftsBA, offset, dlndist) |>
  mutate(hidA = factor(hidA),
         hidB = factor(hidB),
         did = factor(did))
```




The data set can be summarized with the `skimr` package



```{r}
names(dataKL$dyads)
dataKL$dyads |> skim() |>
  select(-n_missing, -complete_rate) |>
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 2))
```

We can visualize the distribution of dyadic gifts using a scatter plot

```{r}
#| fig-cap: "Figure 14.8"
dataKL$dyads |> ggplot(aes(x = giftsAB, y = giftsBA)) +
  geom_point(color = "darkblue") +
  geom_abline(slope = 1, intercept = 0, linetype = 2, color = "royalblue") +
  coord_equal(ratio = 1, xlim = c(0, 120), ylim = c(0, 120)) +
  labs(title = "Distribution of dyadic gifts")
```

and since this a social network then we can visualize the network with the 
`ggnetwork` package.For details see [ggnetwork](https://cran.r-project.org/web/packages/ggnetwork/vignettes/ggnetwork.html).

We use the `tidygraph` to use dplyr verbs on relational data and `ggraph` to
plot it.

```{r}
netKL <- list()
netKL <- within(netKL, {
  # the tbl_graph object
  the_edges <- dataKL$dyads |>
    mutate(giftsSum = abs(giftsAB - giftsBA))
  the_nodes <- dataKL$houses
  grf <- tidygraph::tbl_graph(nodes = the_nodes, edges = the_edges, directed = FALSE)

  colrs <- paletteer::paletteer_c("oompaBase::jetColors", direction = -1, n = 16)
  p <- ggraph(grf, layout = "circle") +
    geom_edge_link(aes(color = dlndist)) +
    geom_node_point(aes(size = hwealth), color = "brown") +
    scale_color_paletteer_c("oompaBase::jetColors", direction = -1) +
    scale_size_continuous(range = c(1, 4)) +
    scale_edge_color_gradientn(colors = colrs) +
    ggraph::theme_graph() +
    theme(title = element_text(color = "midnightblue")) +
    labs(title = "The KosterLeckie Network")
})
netKL$p
```

### Model

$$

\begin{align*}
\begin{bmatrix}
y_{a \rightarrow b} \\
y_{b \rightarrow a} \\
\end{bmatrix}
&\sim
\begin{bmatrix}
\mathcal{Poisson}(\lambda_{AB}) \\
\mathcal{Poisson}(\lambda_{BA}) \\
\end{bmatrix} \\
\log{\lambda_{AB}} &= \alpha + g_A + r_B + d_{AB} \\
\log{\lambda_{BA}} &= \alpha + g_B + r_A + d_{BA} \\
\begin{bmatrix}
g_i \\
r_i \\
\end{bmatrix}
&\sim
\mathcal{MVNormal}(
\begin{bmatrix}
0 \\
0
\end{bmatrix},
\Sigma_{gr}
) \\
\begin{bmatrix}
d_{ij} \\
d_{ji} \\
\end{bmatrix}
&\sim
\mathcal{MVNormal}(
\begin{bmatrix}
0 \\
0
\end{bmatrix},
\Sigma_d
) \\

\Sigma_{gr} &= 
\begin{bmatrix}
\sigma_g & 0 \\
0 & \sigma_r &
\end{bmatrix}
\cdot
\begin{bmatrix}
1 & \rho_{gr} \\
\rho_{gr} & 1 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
\sigma_g & 0 \\
0 & \sigma_r \\
\end{bmatrix} \\

\Sigma_d &= 
\begin{bmatrix}
\sigma_d & 0 \\
0 & \sigma_d &
\end{bmatrix}
\cdot
\begin{bmatrix}
1 & \rho_d \\
\rho_d & 1 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
\sigma_d & 0 \\
0 & \sigma_d \\
\end{bmatrix} \\

\sigma_d, \sigma_g, \sigma_r &\sim \mathcal{Exponential}(1) \\


\rho_{gr}, \rho_d &\sim \mathcal{LKJ}(4)
\end{align*}
$$

Kurtz says that there is no known way to use `brms`. The package `bisonR` 
specializes in social networks and uses `brms`. It can be found at 
[bison](https://github.com/JHart96/bisonR) with a useful vignette at [vignette](https://jordanhart.co.uk/bisonR/articles/getting_started.html).

::: callout-note
This section is skipped. But one day, it might be interesting to do it with the `bisonR` package.
:::

## Continuous categories and the Gaussian process

### Spatial autocorrelation in Oceanic tools

#### Data

The observed data is as follows. All the data is put in 2 dataframes to be able to analyse it as graph data.

-   nodes_df: The data related to the nodes
-   edges_df: The data related to the edges, e.g. the distance between the cultures

First we define the nodes dataframes

```{r}
data(Kline2)
dataKline <- list()
dataKline <- within(dataKline, {
  nodes_df <- Kline2 |>
    mutate(log_pop_s = as.vector(scale(logpop)),
           cid = factor(contact, levels = c("low", "high"))) |>
    # latitude and longitude coverted to thousands of km
    # using the average distance at the equator
    mutate(lat_pos = lat * 0.11132,
           lon2_pos = lon2 * 0.11132)
  })
rm(Kline2)
dataKline$nodes_df |>
  skim() |>
  select(-n_missing, -complete_rate) |>
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 2))
# glimpse(dataKline$df)
```

and we will also use a matrix of the longitudinal and latitudinal relative 
positions of the societies. This is an approximation only as it used the km per 
degree at the equator which is 111.32 km per degree at the equator. This gives 
the following relative position matrix.

```{r}
data(islandsDistMatrix)
dataKline <- within(dataKline, {
  dist <- islandsDistMatrix
  # create the edges dataframe
  edges_df <- dist
  # set lower triangle and diagonal to 0 to avoid double values.
  # zeros can be removed later
  edges_df[lower.tri(edges_df, diag = FALSE)] <- NA_real_
  
  # The distances in dataframe format
  edges_df <- dist |>
    as.data.frame() |>
    tibble::rownames_to_column(var = "x") |>
    pivot_longer(cols = -x, names_to = "y", values_to = "dist")
  })
rm(islandsDistMatrix)
```

and we can visualize the distance in a heatmap

```{r}
heatmaply::heatmaply(
  x = dataKline$dist,
  cellnote = round(dataKline$dist, 1),
  colors = unclass(paletteer::paletteer_c("pals::ocean.speed", n = 16)),
  hide_colorbar = TRUE,
  main = "Distances between Oceanic Societies in Thousands of km")
```

And the basic map, shown as a graph, with latitude and longitude of the culture
can be visualize with the `ggraph` package.

```{r ch14_graph14_08}
#| fig-align: "center"
graph14_08 <- list()
graph14_08 <- within(graph14_08, {
  # create the graph object
  # the manual layout requires a special treatment when using ggraph
  # source for manual layout:
  # https://stackoverflow.com/questions/67756538/plot-ggraph-using-supplied-node-coordinates
  # must add the x and y coords to the nodes for manual layout to work
  the_nodes <- dataKline$nodes_df |>
    select(culture, x = lon2_pos, y = lat_pos, logpop)
  the_edges <- dataKline$edges_df
  grf <- tbl_graph(nodes = the_nodes, edges = the_edges, directed = FALSE)

  # we use a special layout, when the x and y have different names to avoid
  # conflict. See the source on manual layout mentioned above
  p <- ggraph(grf, layout = data.frame(lx = NA, ly = NA)) +
    geom_node_point(aes(color = logpop, size = logpop)) +
    geom_node_text(aes(label = culture), color = "darkblue", size = 4, repel = TRUE) +
    scale_color_paletteer_c("pals::isol") +
    theme(legend.position = "none") +
    labs(title = "Relative positions of societies",
         x = "longitude in thousands of km", y = "latitude in thousands of km")
})
graph14_08$p
```


#### Model

We use the scientific model. See section 11.2.1, p. 356, in the Overthinking box.

$$
\begin{align*}
T_i &\sim \mathcal{Poisson}(\lambda_i) \\
\lambda_i &= \frac{\alpha P_i^\beta}{\gamma}
\end{align*}
$$

and since we need a varying intercept we had one in a *multiplicative form*. We could simply add it but then it could become negative.

$$
\begin{align*}
T_i &\sim \mathcal{Poisson}(\lambda_i) \\
\lambda_i &= \exp(k_{society}) \frac{\alpha P_i^\beta}{\gamma}
\end{align*}
$$

Here $k_{society}$ is the varying intercept. These intercept are part of a 
multivariate distribution. The multivariate intercept prior is defined as

$$
\begin{align*}
\begin{bmatrix}
k_1 \\
k_2 \\
k_3 \\
\vdots \\
k_{10}
\end{bmatrix}
&\sim
\mathcal{MVNormal} \left(
\begin{bmatrix}
0 \\
0 \\
0 \\
\vdots \\
0
\end{bmatrix}
,
\bf{K}
\right) \\
\bf{K} &= \eta^2 \exp(-\rho^2D_{ij}^2) + \delta_{ij}\sigma^2
\end{align*}
$$

::: callout-note
The rest of the section comes from @kurtz2020b who did such a fantastic work at adapting the wonderful *rethinking* to `brms`. I am so grateful for the opportunity to enjoy all this.
:::

::: callout-important
There is a lot more details and info at @kurtz2020b. Please read it to get the full picture.
:::

We could have used $D_{ij}$ instead of $D_{ij}^2$ for $\bf{K}$. $D_{ij}^2$ because of its half-Gaussian shape which is more sigmoidal in shape. As illustrated just below.

```{r}
#| fig-cap: "Figure 14.10"
#| fig-align: "center"
ggplot(data.frame(x = c(0, 4)), aes(x = x)) +
  stat_function(aes(color = "-exp(D)"), fun = function(x) exp(-1 * x), size = 2) +
  stat_function(aes(color = "-exp(D^2)"), fun = function(x) exp(-1 * x^2), size = 2) +
  scale_color_paletteer_d("ggsci::alternating_igv") +
  theme(legend.position = c(0.8, 0.8),
        legend.title = element_blank()) +
  labs(title = "Shape of function relating distance to covariance",
       x = "distance", y = "correlation")
```

Therefore we have the model used by `rethinking` and the one by `brms`

##### `rethinking` model

$$
\begin{align*}
T_i &\sim \mathcal{Poisson}(\lambda_i) \\
\lambda_i &= \exp(k_{society}) \frac{\alpha Population_i^\beta}{\gamma} \\
\begin{bmatrix}
k_1 \\
k_2 \\
k_3 \\
\vdots \\
k_{10}
\end{bmatrix}
&\sim
\mathcal{MVNormal}\left(
\begin{bmatrix}
0 \\
0 \\
0 \\
\vdots \\
0
\end{bmatrix}
,
\bf{K}
\right) \\
\bf{K} &= \eta^2 \exp(-\rho^2Distance_{ij}^2) + \delta_{ij}\sigma^2 \\
\delta_{ij} &= 0 \implies \delta_{ij}\sigma^2 = 0 \; \text{because only 1 observation per island} \\
\alpha, \beta, \gamma &\sim \mathcal{Exponential}(1) \\
\eta^2 &\sim \mathcal{Exponential}(2) \\
\rho^2 &\sim \mathcal{Exponential}(0.5)
\end{align*}
$$ 


##### `brms` model

$$
\begin{align*}
T_i &\sim \mathcal{Poisson}(\lambda_i) \\
\lambda_i &= \exp(k_{society}) \frac{\alpha Population_i^\beta}{\gamma} \\
\begin{bmatrix}
k_1 \\
k_2 \\
k_3 \\
\vdots \\
k_{10}
\end{bmatrix}
&\sim
\mathcal{MVNormal} \left(
\begin{bmatrix}
0 \\
0 \\
0 \\
\vdots \\
0
\end{bmatrix}
,
\bf{K}
\right) \\
\bf{K_{ij}} &= sdgp^2 \exp \left(\frac{-Distance_{ij}^2}{2 \cdot lscale^2} \right) \\
\alpha &\sim \mathcal{N}(0, 1) \\
\beta, \gamma &\sim \mathcal{Exponential}(1) \\
sgdp^2 &\sim \mathcal{Exponential}(1) \\
lscale^2 &\sim \mathcal{InvGammal}(2.874624, 2.941204)
\end{align*}
$$

#### Fit

Since our model is non-linear (scientific formula) then the fit with `brms` uses the non-linear form.

```{r}
#| echo: false
#| output: false
get_prior(data = dataKline$nodes_df,
          formula = bf(total_tools ~ exp(a) * population^b / g,
                  a ~ 1 + gp(lat_pos, lon2_pos, scale = FALSE),
                  b + g ~ 1,
                  nl = TRUE),
          family = poisson)
```

```{r ch14_fit14_08}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "90 secs."))
fit14_08 <- xfun::cache_rds({
  brm(
    data = dataKline$nodes_df,
    family = poisson(link = "identity"),
    formula =  bf(total_tools ~ exp(a) * population^b / g,
                  a ~ 1 + gp(lat_pos, lon2_pos, scale = FALSE),
                  b + g ~ 1,
                  nl = TRUE),
    prior = c(
      prior(normal(0, 1), nlpar = a),
      prior(exponential(1), nlpar = b, lb = 0),
      prior(exponential(1), nlpar = g, lb = 0),
      prior(inv_gamma(2.874624, 2.941204), class = lscale, coef = gplat_poslon2_pos, nlpar = a),
      prior(exponential(1), class = sdgp, coef = gplat_poslon2_pos, nlpar = a)),
    iter = 2000, warmup = 1000, chains = 2,
    sample_prior = TRUE,
    cores = detectCores(), seed = 1433)},
  file = "ch14_fit14_08", rerun = FALSE)
tictoc::toc()
```

which gives the results

```{r}
fit14_08
```

and to have a summary similar to McElreath on p. 472 we can use

```{r}
fit14_08 |>
  summarize_draws("mean", "sd", ~quantile(.x, probs = c(0.055, 0.945)),
                  default_convergence_measures()) |>
  filter(!grepl("^lp", x = variable)) |>
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 2),
         across(.cols = starts_with("ess"), .fns = as.integer))
```

or with `posterior_summary` which is simpler but lacks de ESS

```{r}
posterior_summary(fit14_08) |>
  round(digits = 2)
```

#### Analysis

The differences with `rethinking` are because `brms` uses non-centering. 
The coefficient that is really different is the $\alpha$ in 
$\lambda_i = \exp(k_{society}) \frac{\alpha P_i^\beta}{\gamma}$.

To evaluate the differences between `brms` and `rethinking` we can look at what 
the posterior would be like, without taking into account the covariances.

For `brms` we have

```{r}
pop <- as.integer(c(min(dataKline$nodes_df$population),
             median(dataKline$nodes_df$population),
             max(dataKline$nodes_df$population)))
tools <- as.integer(c(min(dataKline$nodes_df$total_tools),
               mean(dataKline$nodes_df$total_tools),
               max(dataKline$nodes_df$total_tools)))
a <- fixef(fit14_08)["a_Intercept", "Estimate"]
b <- fixef(fit14_08)["b_Intercept", "Estimate"]
g <- fixef(fit14_08)["g_Intercept", "Estimate"]
# brms uses a different equation for lambda
l <- exp(a) * pop ^ b / g
prob_brms <- round(dpois(x = tools, lambda = l), 4)
prob_brms
```

as opposed to `rehinking` which would give

```{r}
a <- 1.41
b <- 0.28
g <- 0.60
# rethinking uses a different equation for lambda
l <- a * pop ^ b / g
prob_rethink <- round(dpois(x = tools, lambda = l), 4)
prob_rethink
```

The results between the 2 are different and cannot really be compared because

-   correlations between $D$ in `rethinking` and $D^2$ in `brms` is not the same and
-   `brms` has a very different way of computing the likelihood

Basically, `rethinking` uses the following definition of $\bf{K_{ij}}$

$$
\bf{K_{ij}} = \eta^2 \exp \left(-\rho^2D_{ij}^2 \right) + \delta_{ij}\sigma^2
$$

where the term $\delta_{ij}\sigma^2$ is used when $i=j$, see p. 470 of 
@elreath2020. In the oceanic case it is not applicable since we have only one 
observation per society. Therefore the equation is this case is

$$
\bf{K_{ij}} = \eta^2 \exp \left(-\rho^2D_{ij}^2 \right)
$$

whereas `brms` uses

$$
\bf{K_{ij}} = sdgp^2 \exp \left(\frac{-D_{ij}^2}{2 \cdot lscale^2} \right)
$$

and so the 2 equations can be compared as follows

$$
\begin{align*}
\eta^2 &= sdgp^2 \\
-\rho^2 &= \frac{1}{2 \cdot lscale^2}
\end{align*}
$$

and we note that the distance used can always be found as follows

$$
\begin{align*}
\bf{K_{ij}} &= sdgp^2 \exp \left(\frac{-D_{ij}^2}{2 \cdot lscale^2} \right) \\
\log \left( \bf{K_{ij}} \right) &= \log \left(sdgp^2 \right) + \frac{-D_{ij}^2}{2 \cdot lscale^2} \\
D_{ij}^2 &= 2 \cdot lscale^2 \cdot \left[ \log \left(sdgp^2 \right) - \log \left( \bf{K_{ij}} \right) \right]
\end{align*}
$$

and therefore we can figure out the covariance and convert the coefficients 
between `brms` and `rethinking`,

```{r}
post14_08 <- list()
post14_08 <- within(post14_08, {
  # function to compute eta squared as per rethinking
  rethink_eta2 <- function(sdgp) {
    sdgp^2
  }
  # function to compute rho squared as per rethinking
  rethink_rho2 <- function(lscale) {
    -1 / (2 * lscale^2)
  }
  # function to calculate the covariance as per brms
  brms_cov <- function(x, sdgp, lscale) {
    sdgp^2 * exp(-(x^2) / 2 * lscale^2)
  }
})
```

and we transform the posterior data to be able to plot as shown in figure 
14.11 on p. 473

```{r ch14_post14_08}
post14_08 <- within(post14_08, {

  post <- tidy_draws(fit14_08)
  
  # the median of the parameters is used later
  stats <- post |>
    select(prior_sdgp_a_gplat_poslon2_pos,
           sdgp_a_gplat_poslon2_pos,
           prior_lscale_a__1_gplat_poslon2_pos,
           lscale_a_gplat_poslon2_pos) |>
    median_qi(.width = 0.89)
  
  set.seed(1433)
  sampl <- post |>
    select(.draw,
           prior_sdgp_a_gplat_poslon2_pos,
           sdgp_a_gplat_poslon2_pos,
           prior_lscale_a__1_gplat_poslon2_pos,
           lscale_a_gplat_poslon2_pos) |>
    mutate(prior_eta2 = rethink_eta2(prior_sdgp_a_gplat_poslon2_pos),
           eta2 = rethink_eta2(sdgp_a_gplat_poslon2_pos),
           prior_rho2 = rethink_rho2(prior_lscale_a__1_gplat_poslon2_pos ),
           rho2 = rethink_rho2(lscale_a_gplat_poslon2_pos)) |>
    slice_sample(n = 50) |>
    expand_grid(dist = seq(from = 0, to = 10, by = 0.05)) |>
    mutate(prior_cov = brms_cov(x = dist,
                                sdgp = prior_sdgp_a_gplat_poslon2_pos,
                                lscale = prior_lscale_a__1_gplat_poslon2_pos),
           cov = brms_cov(x = dist,
                          sdgp = sdgp_a_gplat_poslon2_pos,
                          lscale = lscale_a_gplat_poslon2_pos))
})
# glimpse(post14_08$stats)
# glimpse(post14_08$sampl)
```


```{r ch14_plot14_08}
#| fig-cap: "Figure 14.11"
#| fig-align: "center"
plot14_08 <- list()
plot14_08 <- within(plot14_08, {
  prior <- post14_08$sampl |> ggplot(aes(x = dist, y = prior_cov)) +
    geom_line(aes(group = .draw, color = .draw)) +
    stat_function(
      fun = function(x) {
        post14_08$brms_cov(x = median(post14_08$sampl$dist),
                           sdgp = post14_08$stats$prior_sdgp_a_gplat_poslon2_pos,
                          lscale = post14_08$stats$prior_lscale_a__1_gplat_poslon2_pos)},
      color = "firebrick", linewidth = 1) +
    scale_x_continuous(breaks = scales::breaks_width(width = 2),
                       labels = scales::label_number_auto()) +
    scale_color_paletteer_c("pals::ocean.speed") +
    coord_cartesian(ylim = c(0, 2)) +
    theme(legend.position = "none") +
    labs(title = "Gaussian process prior",
         subtitle = "Red line is the median of the covariances",
         x = "distance in thousands of km",
         y = "covariance")
  post <- post14_08$sampl |> ggplot(aes(x = dist, y = cov)) +
    geom_line(aes(group = .draw, color = .draw)) +
    stat_function(
      fun = function(x) {
        post14_08$brms_cov(x = median(post14_08$sampl$dist),
                           sdgp = mean(post14_08$stats$sdgp_a_gplat_poslon2_pos),
                          lscale = mean(post14_08$stats$lscale_a_gplat_poslon2_pos))},
      color = "firebrick", linewidth = 1) +
    scale_x_continuous(breaks = scales::breaks_width(width = 2),
                       labels = scales::label_number_auto()) +
    scale_color_paletteer_c("pals::ocean.speed") +
    coord_cartesian(ylim = c(0, 2)) +
    theme(legend.position = "none") +
    labs(title = "Gaussian process posterior",
         subtitle = "Red line is the median of the covariances",
         x = "distance in thousands of km",
         y = "covariance")
})
wrap_plots(plot14_08[c("prior", "post")]) +
  plot_annotation(title = "Oceanic Gaussian Process") &
  theme(title = element_text(color = "darkblue"))
```

and to get the matrix of median covariance we simply map the calculation of 
covariance using the median values of the parameters

```{r}
post14_08 <- within(post14_08, {
  # the covariance matrix using the median of the parameters
  # i.e. the median covariance
  # The covariance is calculated based on the distance
  cov <- post14_08$brms_cov(
    x = dataKline$dist,
    sdgp = post14_08$stats$sdgp_a_gplat_poslon2_pos,
    lscale = post14_08$stats$lscale_a_gplat_poslon2_pos)
  # the correlation matrix
  cor <- cov2cor(cov) |>
    round(digits = 2)
})
# post14_08$cor
```

which we can illustrate with a heatmap

```{r}
#| fig-align: "center"
heatmaply::heatmaply_cor(
  x = post14_08$cor,
  cellnote = post14_08$cor,
  colors = unclass(paletteer::paletteer_c("pals::ocean.tempo", n = 16)),
  hide_colorbar = TRUE,
  main = "Correlations between Oceanic Societies in Thousands of km")
```

and we add the correlations to our edges to be able to plot them

```{r}
dataKline <- within(dataKline, {
  # create the correlation dataframe
  cor_df <- post14_08$cor
  # set lower triangle and diagonal to 0 to avoid double values.
  # zeros can be removed later
  cor_df[lower.tri(cor_df, diag = FALSE)] <- NA_real_
  cor_df <- cor_df |>
    as.data.frame() |>
    tibble::rownames_to_column(var = "x") |>
    pivot_longer(cols = -x, names_to = "y", values_to = "cor")
  
  # make sure you don't miss a number
  check <- sum(post14_08$cor[lower.tri(post14_08$cor, diag = TRUE)])
  stopifnot(sum(cor_df$cor, na.rm = TRUE) - check == 0)
  
  # add the correlation to the edges
  edges_df <- edges_df |>
    inner_join(y = cor_df, by = c("x" = "x", "y" = "y"))
  stopifnot(sum(edges_df$cor, na.rm = TRUE) - check == 0)
  
})
```

```{r}
#| fig-cap: "Figure 14.12"
#| fig-align: "center"
graph14_08 <- within(graph14_08, {
  
  # the edges' colors
  colrs <- paletteer::paletteer_c("oompaBase::bluescale", n = 16)
  
  # create the graph object
  # the manual layout requires a special treatment when using ggraph
  # source for manual layout:
  # https://stackoverflow.com/questions/67756538/plot-ggraph-using-supplied-node-coordinates
  # must add the x and y coords to the nodes for manual layout to work
  the_nodes <- dataKline$nodes_df |>
    select(culture, x = lon2_pos, y = lat_pos, logpop)
  the_edges <- dataKline$edges_df |>
    filter(between(cor, 0.01, 1))
  grf <- tbl_graph(nodes = the_nodes, edges = the_edges, directed = FALSE)
  
  # the basic graph
  # when we use the manual layout, when the x and y have different names to avoid
  # conflicts. See the source on manual layout mentioned above
  p1 <- ggraph(grf, layout = data.frame(lx = NA, ly = NA)) +
    geom_node_point(aes(size = logpop), color = "purple") +
    geom_edge_link(aes(color = cor, width = cor)) +
    geom_node_text(aes(label = culture), color = "darkblue", size = 3, repel = TRUE) +
    scale_size_continuous(range = c(1, 4)) +
    scale_edge_width(range = c(0.25, 2)) +
    scale_edge_color_gradientn(colors = colrs) +
    theme(legend.position = "none") +
  labs(title = "Relative positions of societies",
       subtitle = "edges = correlation",
       x = "longitude in thousands of km", y = "latitude in thousands of km")
  
  # and we only need to change the nodes for the graph with tools and population
  the_nodes <- dataKline$nodes_df |>
    select(culture, x = logpop, y = total_tools)
  the_edges <- dataKline$edges_df |>
    filter(between(cor, 0.01, 1))
  grf <- tbl_graph(nodes = the_nodes, edges = the_edges, directed = FALSE)
  
  p2 <- ggraph(grf, layout = data.frame(lx = NA, ly = NA)) +
    geom_node_point(aes(size = x), color = "purple") +
    geom_edge_link(aes(color = cor, width = cor)) +
    geom_node_text(aes(label = culture), color = "darkblue", size = 3, repel = TRUE) +
    scale_size_continuous(range = c(1, 4)) +
    scale_edge_width(range = c(0.25, 2)) +
    scale_edge_color_gradientn(colors = colrs) +
    theme(legend.position = "none") +
  labs(title = "Relations between population and tools",
       subtitle = "edges = correlation",
       x = "log of population", y = "total tools")
})
wrap_plots(graph14_08[c("p1", "p2")]) +
  plot_annotation(title = "Oceanic Gaussian Process") &
  theme(title = element_text(color = "darkblue"))
```

### Phylogenic distance

```{r chap14_dagPhylo}
#| fig-align: "center"
dagPhylo <- list()
dagPhylo <- within(dagPhylo, {
  # ggdag has no built-in method to faciliate using subscripts.
  # This is one way to do it!
  
  # IMPORTANT the nodes labels must be empty
  the_nodes <- c("B1" = "", 
                 "B2" = "", 
                 "G1" = "", 
                 "G2" = "",
                 "U1" = "",
                 "U2" = "")
  
  # IMPORTANT: The text labels must follow the order of the nodes
  text_labels <- c(expression(B[1]), expression(B[2]),
                   expression(G[1]), expression(G[2]),
                   expression(U[1]), expression(U[2]))
  
  dag1 <- ggdag::dagify(G2 ~ G1 + U1, B2 ~ G1 + B1 + U1, U2 ~ U1,
                        outcome = "B2",
                        exposure = c("B1", "G1"),
                        latent = c("U1", "U2"),
                       labels = the_nodes)
  
  p1 <-  dag1 |>
    ggdag::ggdag_status(layout = "sugiyama", node = TRUE) +
    # ggdag::ggdag_status(layout = "kk", node = TRUE) +
    geom_dag_point(aes(color = status)) +
    geom_dag_text(color = "white") +
    scale_color_paletteer_d("ggsci::nrc_npg", na.value = "grey") +
    ggdag::theme_dag_blank(
      panel.background = element_rect(fill = "snow", color = "snow"))
})
dagPhylo$p1
```

```{r}
#| fig-align: "center"
dagPhylo <- within(dagPhylo, {
  dag2 <- ggdag::dagify(
    B ~ G + M + U,
    G ~ M + U,
    M ~ U,
    U ~ P,
    outcome = "B",
    latent = c("P", "U"),
    exposure = c("G", "M")
  )
  p2 <- dag2 |>
    ggdag::ggdag_status(layout = "sugiyama") +
        geom_dag_point(aes(color = status)) +
    geom_dag_text(color = "white") +
    scale_color_paletteer_d("ggsci::nrc_npg", na.value = "grey") +
    ggdag::theme_dag_blank(
      panel.background = element_rect(fill = "snow", color = "snow"))
})
dagPhylo$p2
```

#### Data

The data is as follows

```{r}
data(Primates301, package = "rethinking") 
data(Primates301_nex)
```

We standardize the data

```{r}
dataPrimates <- Primates301 |>
  mutate(name = as.character(name)) |> 
  drop_na(group_size, body, brain) |> 
  mutate(M = as.vector(scale(log(body))),
         B = as.vector(scale(log(brain))),
         G = as.vector(scale(log(group_size))))
dataPrimates |> skim() |>
  select(-n_missing, -complete_rate) |>
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 1))
```

and to plot is we use the `ggtree` package. Details on `ggtree` can be found at [ggtree](https://yulab-smu.top/treedata-book/index.html). It is not available
on CRAN at the time of writing this. You can find it in github and install it
with `devtools::install_github("GuangchuangYu/ggtree")`.

```{r}
# devtools::install_github("GuangchuangYu/ggtree")
ggtree::ggtree(tr = Primates301_nex, layout = "circular", color = "firebrick") +
  geom_tiplab(size = 5/3, color = "darkgrey")
```

#### Model

$$
\begin{align*}
\bf{B} &\sim \mathcal{MVNormal}(\mu, \bf{S})\\
\mu_i &= \alpha + \beta_G G_i + \beta_M M_i \\
\bf{S} &= \sigma^2 \bf{I}
\end{align*}
$$

We begin by fitting a naive model that does not take into account the phylogenetic covariances.

```{r}
#| echo: false
#| output: false
get_prior(
  formula = B ~ M + G,
  data = dataPrimates,
  family = gaussian
)
```

```{r}
#| label: "ch14_fit14_09"
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit14_09 <- xfun::cache_rds({
  brm(
    data = dataPrimates,
    family = gaussian,
    formula =  B ~ M + G,
    prior = c(
      prior(normal(0, 1), class = Intercept),
      prior(normal(0, 0.5), class = b),
      prior(exponential(1), class = sigma)),
    iter = 1000, warmup = 500, chains = 2,
    cores = detectCores(), seed = 1439)},
  file = "ch14_fit14_09", rerun = FALSE)
tictoc::toc()
```

```{r}
fit14_09
```

We use the `ape` package to compute the implied covariance matrix and distance matrix

```{r}
treePhylo <- list()
treePhylo <- within(treePhylo, {
  spp_obs <- dataPrimates$name
  
  tree_trimmed <- ape::keep.tip(Primates301_nex, spp_obs)
  Rbm <- ape::corBrownian(phy = tree_trimmed)
  V <- ape::vcv(Rbm)
  Dmat <- stats::cophenetic(tree_trimmed)
})
```

## Summary

## Practice
