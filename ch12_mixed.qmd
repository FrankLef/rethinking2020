# Monsters and Mixtures {#Mixed}

```{r}
#| include: false
library(dplyr)
library(tidyr)
library(tidybayes)
library(rethinking)
library(brms)
library(qs)
library(loo)
library(modelr)
library(skimr)
library(simpr)
library(posterior)
library(scales)
library(dagitty)
library(ggdag)
library(ggdist)
library(ggmcmc)
library(bayesplot)
library(patchwork)
library(paletteer)
```

Some options to facilitate the computations

```{r}
#  For execution on a local, multicore CPU with excess RAM
options(mc.cores = parallel::detectCores())
#  To avoid recompilation of unchanged Stan programs
rstan::rstan_options(auto_write = TRUE)
```

The default theme used by `ggplot2`

```{r}
theme_set(
  ggthemes::theme_hc(base_size = 12, base_family = "sans", style = "darkunica") +
  theme(title = element_text(color = "floralwhite"),
        axis.title.y = element_text(angle = 90),
        strip.background = element_rect(fill = "darkgrey")))
```

## Over-dispersed outcomes

### Beta-binomial

#### Beta-binomial distribution

The beta distribution is

$$
\mathcal{Beta}(x|\alpha, \beta) =
\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha -1} (1-x)^{\beta -1} =
\frac{1}{B(\alpha, \beta)} x^{\alpha -1} (1-x)^{\beta -1}, 0 \leq x \leq 1
$$

which is not the format used by McElreath. He uses the following shape parameters which are easier (personal opinion) to understand as $\mu$ is the **average** of the distribution and $\kappa$ is the **spread**.

$$
\begin{align*}
\mu &= \bar{p} = \frac{\alpha}{\alpha + \beta} \\
\kappa &= \theta = \alpha + \beta
\end{align*}
$$

The beta-binomial distribution in `brms` is defined with `brms::dbeta_binomial`. This distribution uses the parameters $\mu$ and $\phi$. Now this is confusing because $\mu$ and $\phi$ are actually respectively the beta distribution's $\alpha$ and $\beta$ mentioned above.

So from now on we use the following parameters with the beta-binomial distribution from `brms`

$$
\begin{align*}
\mu \:\text{parameter in brms:} \:\: \alpha &= \mu \cdot \kappa \\
\phi \: \text{phi parameter in brms:} \:\:\beta &= (1-\alpha) \cdot \kappa
\end{align*}
$$

the `simstudy` package provide the function to perform that conversion from $mean = \mu$ and $precision = \kappa$ to the shape (mathematical) parameters $\alpha$ and $\beta$

```{r}
paramsMeanKappa <- list(mean = 0.5, kappa = 5)
paramsShape <- with(paramsMeanKappa, simstudy::betaGetShapes(mean, kappa))
stopifnot(paramsShape$shape1 == paramsMeanKappa$mean * paramsMeanKappa$kappa,
          paramsShape$shape2 == (1 - paramsMeanKappa$mean) * paramsMeanKappa$kappa)
```

Variations of the beta distribution using different parameter values can be illustrated as follows

```{r ch12_plotBeta}
plotBeta <- list()
plotBeta <- within(plotBeta, {
  df <- crossing(pbar = c(0.25, 0.5, 0.75), theta = c(5, 15, 30)) %>% 
  expand(nesting(pbar, theta), 
         x = seq(from = 0, to = 1, length.out = 100)) %>%
  mutate(shape1 = simstudy::betaGetShapes(pbar, theta)$shape1,
         shape2 = simstudy::betaGetShapes(pbar, theta)$shape2) %>%
  mutate(density = dbeta(x, shape1, shape2),
         mu = paste("mu", pbar, sep = "=="),
         kappa = paste("kappa", theta, sep = "=="))
  
  p <- ggplot(data = df, aes(x = x, y = density)) +
    geom_area(fill = "darkorchid1") + 
    scale_y_continuous(NULL, labels = NULL) +
    theme(axis.ticks.y = element_blank()) +
    facet_grid(kappa~mu, labeller = label_parsed) +
    labs(title = "Beta can take many shapes", x = "parameter space")
})
plotBeta$p
```

#### Beta-binomial model

The data used is

```{r ch12_dataAdmit}
data(UCBadmit)
dataAdmit <- UCBadmit %>%
  mutate(gid = ifelse(applicant.gender == "male", "1", "2"))
rm(UCBadmit)
# glimpse(dataAdmit)
```

There is an error in the model defined by McElrath, to concur with his code at 11.26, the model is

$$
\begin{align*}
admit_i &\sim \mathcal{BetaBinomial}(N_i, \bar{p}_i, \phi) \\
logit(\bar{p}_i) &= \alpha_{gid[i]} \\
\alpha &\sim \mathcal{N}(0, 1.5) \\
\phi &\sim \mathcal{Exponential}(1)
\end{align*}
$$

We can fit the model in 2 ways with `brms`: With the `beta_binomilal` family or with a custom family called `beta_binomial2()` as explained by [burkner](https://paul-buerkner.github.io/brms/articles/brms_customfamilies.html). The family `beta_binomial` and `beta_binomila2` give the same results! So we use `brms::beta_binomilal`

```{r}
brms::brmsfamily("beta_binomial")
```

```{r ch12_fit12_01}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit12_01 <- xfun::cache_rds({
  brm(
    data = dataAdmit,
    family = beta_binomial,
    admit | trials(applications) ~ 0 + gid,
    prior = c(prior(normal(0, 1.5), class = b),
              prior(exponential(1), class = phi, lb = 2)),
    iter = 1000, warmup = 500, chains = 2,
    cores = detectCores(), seed = 1201)},
  file = "ch12_fit12_01")
tictoc::toc()
```

```{r}
fit12_01
```

::: callout-note
Did you notice `lb = 2` in `prior(exponential(1), ...)`? Since McElreath wanted the lower bound to 2, we will use lb = 2.
:::

See also McElreath explanation of 2 in section 12.1.1 just before R code 12.1 on p. 371.

and the posterior data which *represents the distribution rather than the data*

```{r}
#| echo: false
#| output: false
get_variables(fit12_01)
```

```{r }
gather_rvars(fit12_01, b_gid1, b_gid2, phi) |>
  ggplot(aes(xdist = .value, y = .variable, fill = .variable)) +
  stat_dots(color = "white", quantiles = 20) +
  theme(legend.position = "none") +
  labs(title = "Posterior distibution of model 12.1",
       x = NULL, y = NULL)
```

To do figure 12.1 a) which represents the posterior distribution of the rate of admission of female applicant, that is the **posterior beta distribution**

```{r ch12_plot12_01_post}
plot12_01_post <- list()
plot12_01_post <- within(plot12_01_post, {
  post_df <- spread_draws(fit12_01, b_gid1, b_gid2, phi) |>
    mutate(p1 = inv_logit_scaled(b_gid1),
           p2 = inv_logit_scaled(b_gid2),
           ndraws = 100)
  set.seed(1201)
  sample_df <- post_df |>
    slice_sample(n = 20) |>
    select(.draw, p1, p2, phi)
  
  # x values used to create the data.frame
  the_x = seq(from = 0, to = 1, by = 0.01)

  beta_df <- purrr::map2_dfr(.x = sample_df$p2, .y = sample_df$phi, .f = function(mu, kappa) {
    shapes = simstudy::betaGetShapes(mean = mu, precision = kappa)
    shape1 = shapes$shape1
    shape1 = shapes$shape1
    data.frame(x = the_x,
               y = dbeta(x = the_x, shape1 = shapes$shape1, shape2 = shapes$shape2),
               p2 = mu,
               phi = kappa)
    }, .id = "id")
  # beta_df
  
  mean_shapes <- simstudy::betaGetShapes(
    mean = mean(beta_df$p2), 
    precision = mean(beta_df$phi))
  beta_mean_df <- data.frame(
    x = the_x) |>
    mutate(
      y = dbeta(x, shape1 = mean_shapes$shape1, shape2 = mean_shapes$shape2))
  
  p <- ggplot(data = beta_df, aes(x = x, y = y, group = id)) +
    geom_line(color = "yellow") +
    geom_line(data = beta_mean_df, aes(x = x, y = y), inherit.aes = FALSE,
              color = "green", linewidth = 2) +
    coord_cartesian(ylim = c(0, 3)) +
    labs(title = "Distribution of female admission rates",
         x = "probability admit", y = "density")
  
})
plot12_01_post$p
```

and for the posterior validity check

```{r ch12_plot12_01_epred}
plot12_01_epred <- list()
plot12_01_epred <- within(plot12_01_epred, {
  epred <- dataAdmit |>
    add_epred_draws(fit12_01, ndraws = 100) |>
    mean_qi(.width = 0.89) |>
    mutate(p = admit / applications,
           p_epred = .epred / applications,
           p_lower = .lower / applications,
           p_upper = .upper / applications)
  
  p <- ggplot(epred, aes(x = .row, y = p)) +
    geom_point(color = "yellow", size = 3) +
    geom_pointinterval(aes(x = .row, y = p_epred, ymin = p_lower, ymax = p_upper),
                       inherit.aes = FALSE, shape = 1, fatten_point = 7, size = 1, color = "green") +
    scale_x_continuous(breaks = scales::breaks_width(width = 1)) +
    scale_y_continuous(breaks = scales::breaks_extended(n = 7),
                       labels = scales::label_percent()) +
    labs(title = "Posterior validity check",
         subtitle = "with 89% CI",
         x = "case", y = "admission rate")
})
# plot12_01_epred$epred
plot12_01_epred$p
```

### Negative-binomial or gamma-Poisson

::: callout-important
You absolutely need to look at the Poisson-lognormal mixture in Kurtz's blog [Kurtz lognormal](https://solomonkurz.netlify.app/post/2021-07-12-got-overdispersion-try-observation-level-random-effects-with-the-poisson-lognormal-mixture/).
:::

#### Gamma-Poisson distribution shape

In terms of the shape $\alpha$ and rate $\beta$ the gamma distribution is

$$
\mathcal{Gamma}(y \mid\alpha, \beta) = \frac{\beta^\alpha y^{\alpha-1} e^{-\beta y}}{\Gamma(\alpha)}
$$

but the rate $\beta$ and scale $\theta$ are the reciprocal of each other. Therefore the gamma distribution can be expressed in terms of shape $\alpha$ and scale $\theta$ as

$$
\mathcal{Gamma}(y \mid\alpha, \theta) = \frac{y^{\alpha-1} e^{-\frac{y}{\theta}}}{\theta^\alpha\Gamma(\alpha)}
$$

and, also, the gamma distribution can be expressed in terms of mean $\mu$ and shape $\alpha$

$$
\mathcal{Gamma}(y \mid \mu, \alpha) = 
\frac{(\frac{\alpha}{\mu})^\alpha}{\Gamma(\alpha)}
y^{\alpha-1} \exp{(-\frac{\alpha y}{\mu})}
$$

To convert from the $\mu = mean$ and $\theta = dispersion= \frac{mean^2}{variance}$ to the shape and rate parameters we use the function `simstudy::gammaGetShapeRate()`. To help us find the mean and dispersion to use with `simstudy::gammaGetShapeRate()`, the custom function `gammaGetMeanDispersion` is also defined. It is the inverse of `simstudy::gammaGetShapeRate()`.

```{r}
# custom function which is the inverse function of gammaGetShapeRate()
gammaGetMeanDispersion <- function(shape, rate) {
  stopifnot(shape > 0, rate > 0)
  dispersion <- 1 / shape
  mean <- shape / rate
  list("mean" = mean, "dispersion" = dispersion)
}

# test it
prm <- list()
prm <- within(prm, {
  values <- list(mean = 1, dispersion = 10)
  # get the shape and rate from the mean and dispersion
  sr <- simstudy::gammaGetShapeRate(mean = values$mean, dispersion = values$dispersion)
  # using the inverse should take you back to the mean and dispersion
  md <- gammaGetMeanDispersion(shape = sr$shape, rate = sr$shape)
})
# using the inverse should take you back to the mean and dispersion
stopifnot(identical(prm$md, prm$values))
```

In the `dgamma` the shape parameter influence the rate which is equivalent to Poisson $\lambda$.

```{r ch12_plotGamma}
plotGamma <- list()
plotGamma <- within(plotGamma, {
  df <- crossing(shape = c(0.5, 1, 2), 
                 rate = c(0.25, 0.5, 1)) |>
    expand(nesting(shape, rate), 
           x = seq(from = 0, to = 5, length.out = 50)) |>
    mutate(density = dgamma(x, shape, rate),
           shape_lbl    = paste("shape", format(shape, nsmall = 2), sep = "=="),
           rate_lbl = paste("rate", format(rate, nsmall = 2), sep = "=="))
  
  p <- df |>
    ggplot(aes(x = x, y = density)) +
    geom_area(fill = "orchid") +
    scale_y_continuous(NULL, labels = NULL) +
    theme(axis.ticks.y = element_blank()) +
    facet_grid(shape_lbl~rate_lbl, labeller = label_parsed) +
    labs(title = "Gamma prior with different parameter values",
       x = "domain space")
})
plotGamma$p
```

#### Data

```{r}
data(Kline)
dataKline <- Kline |>
  mutate(log_pop_s = log(population),
         log_pop_s = as.vector(scale(log_pop_s)),
         cid = factor(contact, levels = c("low", "high")))
rm(Kline)
dataKline |> skim() |>
  select(-n_missing, - complete_rate) |>
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 1))
```

#### Null model {.unnumbered}

::: callout-note
This section is important as it serves to evaluate the prior to use for the full model. See how @kurtz2020b does it. My work below does not show everything (yet).
:::

Start with the null model, or as Kurtz calls it, the intercept-only model.

$$
\begin{align*}
total\_tools_i &\sim \mathcal{GammaPoisson}(\mu, \alpha) \\
log(\mu) &= \beta_0 \\
\beta_0 &\sim \mathcal{Normal}(3, 0.5) \\
\alpha &\sim \mathcal{Gamma}(0.01,0.01)
\end{align*}
$$

```{r ch12_fit12_02a}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit12_02a <- xfun::cache_rds({
  out <- brm(data = dataKline,
      family = negbinomial,
      total_tools ~ 1,
      prior = c(prior(normal(3, 0.5), class = Intercept),  # beta_0
                prior(gamma(0.01, 0.01), class = shape)),  # alpha
      iter = 1000, warmup = 500, chains = 2,
      cores = detectCores(), seed = 1213)
  out <- brms::add_criterion(out, criterion = c("waic", "loo"))
  out},
  file = "ch12_fit12_02a")
tictoc::toc()
```

```{r}
fit12_02a
```

and the estimated parameters of the $mean$ and $dispersion$ can be converted to the $shape$ and $rate$ parameters using $simstudy::gammaGetShapeRate()$

```{r}
m <- posterior_summary(fit12_02a)["b_Intercept", "Estimate"]
d <- posterior_summary(fit12_02a)["shape", "Estimate"]
simstudy::gammaGetShapeRate(mean = m, dispersion = d)
```

Because the model has only the intercept and no predictor, there is only one value for the Intercept which is the mean of the 10 Poisson rates $\lambda_i, i =1,...10$.

The $alpha$ is simply the $shape$ parameter of gamma ... and does not really describe anything. It is really used to define the shape of the distribution.

And the prediction plots show that the distributions using the same rate and shape for the gamma hyperparameters.

```{r ch12_plot12_02a_pred}
plot12_02a_pred <- list()
plot12_02a_pred <- within(plot12_02a_pred, {
  df <- dataKline |>
    add_predicted_draws(fit12_02a, ndraws = 100)
  
  p <- df |>
    ggplot(aes(x = .prediction, color = culture)) +
    geom_density(size = 1) +
    scale_y_continuous(NULL, labels = NULL) +
    scale_color_paletteer_d("khroma::soil") +
    theme(axis.text.x = element_text(size = rel(0.8)),
          axis.ticks.y = element_blank(),
          legend.position = "none") +
    facet_wrap(. ~ culture, nrow = 4) +
    labs(title = "Predictive distributions",
         subtitle = sprintf("Gamma hyperparameters: mean = %0.2f and dispersion = %0.2f",
                            posterior_summary(fit12_02a)["b_Intercept", "Estimate"],
                            posterior_summary(fit12_02a)["shape", "Estimate"]),
        x = "total tools")
})
plot12_02a_pred$p
```

and we can also visualize the distributions of our $rate$ and $shape$ parameters

```{r ch12_plot12_02a_post}
plot12_02a_post <- list()
plot12_02a_post <- within(plot12_02a_post, {
  df <- gather_draws(fit12_02a, b_Intercept, shape, ndraws = 100) |>
    mutate(.variable = if_else(.variable == "b_Intercept", "mean", "dispersion"))
  p <- df |>
    ggplot(aes(.value, fill = .variable, color = .variable)) +
    stat_density(geom = "area") +
    scale_y_continuous(NULL, labels = NULL) +
    scale_fill_paletteer_d("fishualize::Scarus_quoyi") +
    scale_color_paletteer_d("fishualize::Scarus_quoyi") +
    theme(axis.text.x = element_text(size = rel(0.8)),
        axis.ticks.y = element_blank(),
        legend.position = "none") +
    labs(title = "Posterior distributions of rate and shape",
       x = NULL) +
    facet_wrap(. ~ .variable, scales = "free_y")
})
plot12_02a_post$p
```

#### Full model {.unnumbered}

$$
\begin{align*}
total\_tools_i &\sim \mathcal{GammaPoisson}(\mu_i, \alpha) \\
log(\mu) &= \frac{\exp{(\beta_{0,cid[i]})} \cdot population_i^{\beta_{1,cid[i]}}}{\gamma} \\
\beta_{0,j} &\sim \mathcal{Normal}(1, 1) \\
\beta_{1,j} &\sim \mathcal{Exponential}(1) \\
\gamma &\sim \mathcal{Exponential}(1) \\
\alpha &\sim \mathcal{Exponential}(1)
\end{align*}
$$

```{r ch12_fit12_02b}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "30 secs."))
fit12_02b <- xfun::cache_rds({
  # we have to be careful when using waic with gamma-Poisson
  # but in this case we do it. We use t in the plot.
  out <- brm(data = dataKline,
      family = negbinomial(link = "identity"),
      bf(total_tools ~ exp(b0) * population^b1 / g,
         b0 + b1 ~ 0 + cid,
         g ~ 1,
         nl = TRUE),
      prior = c(prior(normal(1, 1), nlpar = b0),
                prior(exponential(1), nlpar = b1, lb = 0),
                prior(exponential(1), nlpar = g, lb = 0),
                prior(exponential(1), class = shape)),
      iter = 1000, warmup = 500, chains = 2,
      cores = detectCores(), seed = 1213,
      control = list(adapt_delta = .95))
  out <- brms::add_criterion(out, criterion = c("waic", "loo"))
  out},
  file = "ch12_fit12_02b")
tictoc::toc()
```

```{r}
fit12_02b
```

add the *pareto k* for use in the plot later

```{r}
# append k value to data
dataKline <- dataKline |>
  mutate(ParetoK = fit12_02b$criteria$loo$diagnostics$pareto_k)
stopifnot(!any(is.na(dataKline)))

dataKline |>
  select(culture, ParetoK) |>
  arrange(desc(ParetoK))
```

and the fitted values are

```{r ch12_epred12_02b}
epred12_02b <- list()
epred12_02b <- within(epred12_02b, {
  df <- dataKline |>
  distinct(cid, culture) |>
  expand(nesting(cid, culture), 
         population = seq_range(dataKline$population, n = 20, pretty = TRUE)) |>
    add_epred_draws(fit12_02b, ndraws = 100) |>
    ggdist::mean_qi(.width = 0.89)
  
  p <- ggplot(dataKline,
                aes(x = population, y = total_tools, color = cid, size = ParetoK)) +
  geom_smooth(df,
              mapping = aes(x = population, y = .epred, ymin = .lower,
                            ymax = .upper, fill = cid, color = cid),
              inherit.aes = FALSE, stat = "identity") +
  geom_point(show.legend = FALSE) +
  ggrepel::geom_text_repel(aes(label = culture), size = 3) +
  scale_x_continuous(breaks = scales::breaks_extended(n = 5),
                     labels = scales::label_number(scale = 0.001)) +
  scale_color_paletteer_d("khroma::light") +
  scale_fill_paletteer_d("khroma::light") +
  scale_size_continuous() +
  theme(legend.position = c(0.2, 0.85)) +
  labs(title = "Fitted values with the gamma-Poisson model",
       subtitle = "model 12.2b",
       x = "population in thousands")
  
  
})
# epred12_02b$df
epred12_02b$p
```

the main difference now is that since we use predictor $cid$ then the parameter $rate = b_0$ of the gamma distribution used to determined the $\lambda_i$ is allowed to vary by $cid$. Therefore we have different possible distribution by $cid$ and can change the distribution by culture as follows.

```{r ch12_pred12_02b}
pred12_02b <- list()
pred12_02b <- within(pred12_02b, {
  
  df <- dataKline |>
    distinct(cid, culture) |>
    expand(nesting(cid, culture), 
          population = seq_range(dataKline$population, n = 20, pretty = TRUE)) |>
    add_predicted_draws(fit12_02b, ndraws = 100)
  
  p <- df |>
    ggplot(aes(x = .prediction, color = cid, fill = cid)) +
    geom_density() +
    scale_color_paletteer_d("khroma::light") +
    scale_fill_paletteer_d("khroma::light") +
    coord_cartesian(xlim = c(0, 200)) +
    theme(axis.text.x = element_text(size = 8),
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank()) +
    labs(title = "Predictive distributions by culture colored by cid",
          subtitle = "model 12.2b", x = "total tools", y = NULL) +
  facet_wrap(. ~ culture)
})
pred12_02b$p
```

### Poisson-lognormal {.unnumbered}

::: callout-tip
This is an extra section. The result is so useful it is worth adding here. See [Kurtz lognormal](https://solomonkurz.netlify.app/post/2021-07-12-got-overdispersion-try-observation-level-random-effects-with-the-poisson-lognormal-mixture/).
:::

## Zero-inflated outcomes

::: callout-tip
Make sure you read this section in @kurtz2020b. It is loaded with very useful informations. Especially when using `brms`.
:::

### Zero-inflated Poisson

This type of model is called a *hurdle model* in the literature. This type of model has served me very well in the context of business.

With zero-inflated Poisson both parameters $p$ and $\lambda$ can have their own equation.

$$
\begin{align*}
prod_i &\sim \mathcal{ZIPoisson}(p_i, \lambda_i) \\
logit(p_i) &= \alpha_p + \beta_p x_i \\
log(\lambda_i) &= \alpha_\lambda + \beta_\lambda x_i \\
\end{align*}
$$

We use `simstudy` to simulate this.

```{r ch12_simMonastery}
simMonastery <- list()
simMonastery <- within(simMonastery, {
  data <- simpr::specify(
    drink = ~ rbinom(n = 1, size = 1, prob = 0.2),
    work = ~ rpois(n = 1, lambda = 1),
    output = ~ (1 - drink) * work) |>
    generate(365) |>
    unnest(sim) |>
    mutate(fdrink = if_else(drink != 0, "drink", "drinkNot"),
           fdrink = as.factor(fdrink))
})
# simMonastery$data |>
#   glimpse()
```

plot the data

```{r}
simMonastery$data |>
  ggplot(aes(x = output)) +
  geom_histogram(aes(fill = fdrink), binwidth = 1) +
  scale_fill_paletteer_d("khroma::vibrant") +
  stat_bin(aes(y = after_stat(count), label = ifelse(after_stat(count), after_stat(count), "")), 
           geom = "text", bins = 30, color = "ghostwhite", vjust = -0.5) +
  theme(legend.position = c(0.8, 0.8),
        legend.title = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) +
  labs(title = "Frequency of monastery's output",
       subtitle = sprintf("output for %d days", nrow(simMonastery$data)),
       y = "nb of days")
```

#### Model and fit

$$
\begin{align*}
prod_i &\sim \mathcal{ZIPoisson}(p, \lambda) \\
logit(p) &= \alpha_p \\
log(\lambda) &= \alpha_\lambda \\
\alpha_p &\sim \mathcal{Beta}(2, 6) \\
\alpha_\lambda &\sim \mathcal{N}(1, 0.5)
\end{align*}
$$

In `brms`, $p_i$ is denoted `zi`. To use a non-default prior for `zi`, make sure to indicate `class = zi`. **Important to read @kurtz2020b**.

```{r ch12_fit12_03}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "65 secs."))
fit12_03 <- xfun::cache_rds({
  out <- brm(data = simMonastery$data,
      family = zero_inflated_poisson,
      output ~ 1,
      prior = c(prior(normal(1, 0.5), class = Intercept),
                prior(beta(2, 6), class = zi)),  # the brms default is beta(1, 1)
      iter = 1000, warmup = 500, chains = 2,
      cores = detectCores(), seed = 1217)
  brms::add_criterion(out, criterion = c("waic", "loo"))},
  file = "ch12_fit12_03")
tictoc::toc()
```

and we generate a summary with `posterior::summarize_draws`

```{r ch12_summ_fit12_03}
summ_fit12_03 <- list()
summ_fit12_03 <- within(summ_fit12_03, {
  data <- as_draws(fit12_03) |>
    mutate_variables(lambda = exp(b_Intercept))
  
  stats <- data |>
    summarize_draws() |>
    filter(variable != "lp__") |>
    mutate(across(.cols = where(is.numeric), round, digits = 2))
})
summ_fit12_03$stats
```

The $b_Intercept$ represents $\lambda$ on the log scale, because the link function for $\lambda$. This can be confirmed by looking at the summary which shows **Links: mu = log; zi = identity**.

We observe that $lambda$ matches the actual rate of our simulation with `defData(defs, varname = "work", dist = "poisson", formula = 1)`.

When using `brms` the parameter $zi$ has link function *identity* as evidenced in the summary by **Links: mu = log; zi = identity**. In this case we have obtained $zi = 0.20$ which is close enough to McEleath's estimate of 0.23.

We observe that $zi$ is the actual rate of our simulation with `defData(varname = "drink", dist = "categorical", formula = "0.8;0.2")`.

## Ordered categorical outcomes

### Example: Moral intuition

```{r}
data(Trolley)
dataTrolley <- Trolley |>
  mutate(response = factor(response, ordered = TRUE))
rm(Trolley)
dataTrolley |>
  skim() |>
  select(-n_missing, -complete_rate) |>
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 2))
```

### Describing and ordered distribution with intercepts

The histogram of response

```{r ch12_plotTrolley}
plotTrolley <- list()
plotTrolley <- within(plotTrolley, {
  df <- dataTrolley |>
    count(response)
  freq <- df |>
    ggplot(aes(x = response, y = n, fill = response)) +
    geom_bar(stat = "identity") +
    scale_fill_paletteer_d("khroma::bright") +
    theme(legend.position = "none") +
    labs(title = "Histogram of Trolley responses")
})
# plotTrolley$freq
```

The cumulative proportions plot

```{r}
plotTrolley <- within(plotTrolley, {
  df2 <- dataTrolley |>
    count(response) |>
    arrange(response) |>
    mutate(pct = n / sum(n),
          cum_pct = cumsum(pct))
  cumfreq <- ggplot(df2, aes(x = as.integer(response), y = cum_pct)) +
    geom_line(color = "yellow", size = 1) +
    geom_point(color = "orange", size = 2) +
    coord_cartesian(ylim = c(0, 1)) +
    labs(title = "Cumulative proportions", 
       x = "response", y = "cumulative probabilities")
})
# plotTrolley$cumfreq
```

And the plot of `logit`

```{r}
plotTrolley <- within(plotTrolley, {
  df3 <- dataTrolley |>
    count(response) |>
    mutate(pct = n / sum(n),
         cum_pct = cumsum(pct),
         logit = log(cum_pct / (1 - cum_pct)),
         logit_ctr = scale(logit, center = TRUE, scale = FALSE))

  center <- df3 |>
    ggplot(aes(x = as.integer(response), y = logit)) +
    geom_line(color = "pink", size = 1) +
    geom_point(color = "violetred", size = 2) +
    labs(title = "Log of Cumulative Odds",
       y = "log of cumulative odds (centered)")
})
# plotTrolley$center
```

and the 3 plots in figure 12.4 are

```{r}
#| fig-cap: "Figure 12.4"
wrap_plots(plotTrolley[c("freq", "cumfreq", "center")]) +
  plot_annotation(title = "Figure 12.4")
```

The model is

$$
\begin{align*}
response_i &\sim \mathcal{Categorical}(\overrightarrow{p}) \\
logit(p_k) &= \alpha_k - \phi \\
\phi &= 0 \\
\alpha_k &\sim \mathcal{N}(0, 1.5)
\end{align*}
$$

and the fit with brms

```{r ch12_fit12_04}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "5 mins."))
fit12_04 <- xfun::cache_rds({
  # define start values
  inits <- list(
    `Intercept[1]` = -2,
    `Intercept[2]` = -1,
    `Intercept[3]` = 0,
    `Intercept[4]` = 1,
    `Intercept[5]` = 2,
    `Intercept[6]` = 2.5)
  inits_list <- list(inits, inits, inits, inits)
  out <- brm(
    data = dataTrolley,
    family = cumulative,
    response ~ 1,
    prior = c(
      prior(normal(0, 1.5), class = Intercept)),
    # the start values
    init = inits_list,
    iter = 1000, warmup = 500, chains = 2,
    cores = detectCores(), seed = 1223)
  brms::add_criterion(out, criterion = c("waic", "loo"))},
  file = "ch12_fit12_04")
tictoc::toc()
```

which gives the summary

```{r}
print(fit12_04)
```

and we convert the intercepts to the normal scale

```{r}
fit12_04 |>
  fixef() |>
  brms::inv_logit_scaled() |>
  round(digits = 3)
```

::: callout-warning
The SD i.e. `Est.Error` are not valid using the `inv_logit_scaled`, that is using a direct inverse exp function.
:::

They must be computed using a posterior sample.

```{r ch12_summ12_04}
summ12_04 <- list()
summ12_04 <- within(summ12_04, {
  data <- tidy_draws(fit12_04)
  summ <- data |>
    select(!matches(match = "__$|disc|lprior|chain|draw|iteration")) |>
    mutate(across(.cols = where(is.double), .fns = ~gtools::inv.logit(.))) |>
    pivot_longer(cols = everything()) |>
    mutate(name = sub(pattern = "^X[[:digit:]][.]b_", replacement = "", x = name),
           name = sub(pattern = "[.]$", replacement = "]", x = name),
           name = sub(pattern = "[.]", replacement = "[", x = name)) |>
    group_by(name) |>
    ggdist::mean_qi(.width = 0.89) |>
    mutate(across(.cols = where(is.numeric), .fns = round, digits = 3))
})
# glimpse(samples$data)
# glimpse(samples$summ)
summ12_04$summ
```

and to validate our fit, we see that the $value$ in the summary is the same as the $cum_pct$ previously computed.

```{r}
plotTrolley$df3$cum_pct |>
  round(digits = 3)
```

### Adding predictor variables

::: callout-note
This form automatically ensure the correct ordering of the outcome values, while still morphing the likelihood of each individual value as the predictor $x_i$ changes value. Why is the linear model $\phi$ substracted from each intercept? Because if we decrease the log-cumulative-odds of every outcome value $k$ below the maximum, this necessarily shifts probability mass upwards towards higher outcome values.
:::

$$
\begin{align*}
\log{\left[ \frac{Pr(y_i \le k)}{1-Pr(y_i \le k)} \right]} &= \alpha_k - \phi_i \\
\phi_i &= \beta x_i
\end{align*}
$$

For example lets take model b12.4

```{r}
fixef(fit12_04)
```

#### Logistic / Logit functions

See the appendix A of this book for a detailed treatment of all these functions. They will be added the suffix *.new* to identify them.

The `logistic()` and `inv_logit()` functions are actually the same as `stats::plogis()`.

Also, the function `logit()` already exists as `stats::qlogis()`.

therefore `dordlogit()` as given

```{r}
dordlogit.new <- function(x, phi = 0L, log = FALSE) {
  x <- sort(x)  # the ordering is important
  p <- stats::plogis(q = c(x, Inf), location = phi)
  p <- c( p[1], p[2:length(p)] - p[1:(length(p)-1)] )
  if (log) p <- log(p)
  p
}
```

which gives about the same result as R code 11.9 in McElreath on p. 386 with R code 12.20, and Kurtz.

```{r}
probk <- dordlogit.new(fixef(fit12_04)[, 1])
round(probk, 2)
```

which gives and expected value of

```{r}
sum(1:7 * probk)
```

#### Subtracting from the log-cumulative odds

If we subtract from the *log-cumulative odds* then we shift the probability mass to higher outcome values.

For example with model b12.4

```{r}
probk <- dordlogit.new(fixef(fit12_04)[, 1])
round(probk, 2)
```

which gives an expected value

```{r}
sum(1:7 * probk)
```

but if we substract 0.5

```{r}
(dordlogit.new(fixef(fit12_04)[, 1], phi = 0.5))
```

then we have a higher expected value

```{r}
sum(dordlogit.new(fixef(fit12_04)[, 1], phi = 0.5) * 1:7)
```

#### Ordered categorical with several predictors

Our model with several predictors is

$$
\begin{align*}
response_i &\sim Categorical(\overrightarrow{p}) \\
logit(Pr(y_i \leq k)) &= \frac{Pr(y_i \leq k)}{1 - Pr(y_i \leq k)}  = \alpha_k - \phi_i \\
\phi_i &= \beta_{action} \cdot action_i + \beta_{intention} \cdot intention_i +  \beta_{contact} \cdot contact_i + \beta{a,i} \cdot(action_i \times intention_i) +
\beta{c,i} \cdot(contact_i \times intention_i) \\
\alpha_k &\sim \mathcal{N}(0, 1.5) \\
\beta_{\bullet} &\sim \mathcal{N}(0, 0.5)
\end{align*}
$$

and the fit is

```{r ch12_fit12_05}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "6 mins."))
fit12_05 <- xfun::cache_rds({
  out <- brms::brm(data = dataTrolley,
                   family = cumulative,
                   formula = response ~ 1 + action + intention + contact +
                     action:intention + contact:intention,
                   prior = c(prior(normal(0, 1.5), class = Intercept),
                             prior(normal(0, 0.5), class = b)),
                   iter = 1000, warmup = 500, chains = 2,
                   cores = detectCores(), seed = 1229)
  brms::add_criterion(out, criterion = c("waic", "loo"))},
  file = "ch12_fit12_05")
tictoc::toc()
```

```{r}
fit12_05
```

and plot the coefficients

```{r}
#| echo: false
#| output: false
get_variables(fit12_05)
```

```{r ch12_post12_05}
post12_05 <- gather_draws(model = fit12_05, `b_action.*`, `b_contact.*`, `b_intention.*`,
                           regex = TRUE)

post12_05 |> 
  ggplot(aes(x = .value, y = .variable)) +
  geom_vline(xintercept = 0, alpha = 1/5, linetype = 3) +
  stat_gradientinterval(.width = .5, size = 1, point_size = 3/2, shape = 21,
                      point_fill = "darkgreen",
                      fill ="green",
                      color = "darkgreen") +
  scale_x_continuous("marginal posterior", breaks = -5:0 / 4) +
  coord_cartesian(xlim = c(-1.4, 0)) +
  labs(x = "marginal posterior", y = NULL,
       title = "Model b12.5 coefficients")
```

## Ordered categorical predictors

### Dirichlet distribution

The Dirichlet distribution, used in this section, can be illustrated as follows

```{r}
set.seed(1805)  # seed from McElreath
dp <- gtools::rdirichlet(10, alpha = rep(2, 7))  %>%
  data.frame() %>%
  setNames(1:7) %>%
  mutate(row = seq_len(nrow(.))) %>%
  pivot_longer(cols = -row, names_to = "index", values_to = "prob")

ggplot(dp, aes(x = index, y = prob, group = row)) +
  geom_line(aes(color = row == 3)) +
  geom_point(aes(color = row == 3)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "lightgreen")) +
  theme(legend.position = "none") +
  labs(title = "Dirichlet distribution",
       subtitle = "Figure 12.7",
       x = "index of variable in vector",
       y = "probability")
```

NOTE: The `brms` package also has a `rdirchlet()` function which is very useful when investigating priors. See @kurtz2020b for details.

### Data

```{r}
data(Trolley)
dataTrolley <- Trolley
rm(Trolley)
dataTrolley <- dataTrolley |> 
  mutate(edu_new = 
           recode_factor(edu,
                  "Elementary School" = 1,
                  "Middle School" = 2,
                  "Some High School" = 3,
                  "High School Graduate" = 4,
                  "Some College" = 5, 
                  "Bachelor's Degree" = 6,
                  "Master's Degree" = 7,
                  "Graduate Degree" = 8,
                  .ordered = TRUE) |>
           as.integer())

dataTrolley |> 
  distinct(edu, edu_new) |> 
  arrange(edu_new)
```

### Model and fit

The model is

$$
\begin{align*}
response_i &\sim \mathcal{Categorical}(\overrightarrow{\textbf{p}}) \\
logit(p_k) &= \alpha_k - \phi_i \\
\phi_i &= \beta_E \sum_{j=0}^{E_i-1} \delta_j + \beta_A \cdot action_i + \beta_I \cdot intention_i + \beta_C \cdot contact_i \\
\alpha_k &\sim \mathcal{N}(0,1.5) \\
\beta_A, \beta_I, \beta_C &\sim \mathcal{N}(0,1) \\
\beta_E &\sim \mathcal{N}(0, 0.143) \\
\overrightarrow{\mathbf{\delta}} &\sim \mathcal{Dirichlet}([2,2,2,2,2,2,2])
\end{align*}
$$

```{r ch12_fit12_06}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "35 mins."))
fit12_06 <- xfun::cache_rds({
  out <- brm(data = dataTrolley,
      family = cumulative,
      response ~ 1 + action + contact + intention + mo(edu_new),  # note the `mo()` syntax
      prior = c(prior(normal(0, 1.5), class = Intercept),
                prior(normal(0, 1), class = b),
                # note the new kinds of prior statements
                # for monotonic variable edu_new
                prior(normal(0, 0.143), class = b, coef = moedu_new),
                prior(dirichlet(2, 2, 2, 2, 2, 2, 2), class = simo, coef = moedu_new1)),
      iter = 1000, warmup = 500, chains = 2,
      cores = detectCores(), seed = 1231)
  brms::add_criterion(out, criterion = c("waic", "loo"))},
  file = "ch12_fit12_06")
tictoc::toc()
```

```{r}
fit12_06
```

```{r}
delta_labels <- c("Elem", "MidSch", "SHS", "HSG", "SCol", "Bach", "Mast", "Grad")

dp <- fit12_06 |>
  tidy_draws() |>
  select(contains("simo_moedu_new1")) |>
  setNames(paste0(delta_labels[2:8], "~(delta[", 1:7, "])")) |>
  identity()
# glimpse(dp)

GGally::ggpairs(dp, labeller = label_parsed) +
  ggthemes::theme_hc() +
  theme(strip.text = element_text(size = 8))
```

## Summary
